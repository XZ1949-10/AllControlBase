#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸€é”®è‡ªåŠ¨è°ƒä¼˜å·¥å…· v1.0

è‡ªåŠ¨æ”¶é›†è¯é¢˜å¸§ç‡å’Œè¯Šæ–­æ•°æ®ï¼Œåˆ†æåç›´æ¥ç”Ÿæˆè°ƒä¼˜é…ç½®æ–‡ä»¶ã€‚

ä½¿ç”¨æ–¹æ³•:
  # ä¸€é”®è°ƒä¼˜ (æ”¶é›†30ç§’æ•°æ®åè‡ªåŠ¨ç”Ÿæˆè°ƒä¼˜é…ç½®)
  python -m tools.tuning.auto_tune --duration 30
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python -m tools.tuning.auto_tune --duration 30 --output tuned_turtlebot1.yaml
  
  # ç›´æ¥åº”ç”¨åˆ°é…ç½®æ–‡ä»¶
  python -m tools.tuning.auto_tune --duration 30 --apply

è¾“å‡º:
  - è°ƒä¼˜åçš„é…ç½®æ–‡ä»¶ (é»˜è®¤: tuning_output/tuned_turtlebot1.yaml)
  - è¯¦ç»†çš„åˆ†ææŠ¥å‘Š (tuning_output/auto_tune_report.txt)
"""

import argparse
import time
import json
import yaml
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict
import numpy as np
from datetime import datetime
import sys
import copy


# =============================================================================
# é…ç½®å¸¸é‡
# =============================================================================
DEFAULT_CONFIG_PATH = "controller_ros/config/platforms/turtlebot1.yaml"
DEFAULT_OUTPUT_DIR = "tuning_output"

# è¯é¢˜é…ç½® - åŸºäº turtlebot1.yaml å’Œ controller_params.yaml
TOPICS_CONFIG = {
    'odom': {
        'topic': '/odom',
        'msg_type': 'nav_msgs/Odometry',
        'param': 'watchdog.odom_timeout_ms',
        'expected_hz': 50,
        'timeout_margin': 2.0,
    },
    'trajectory': {
        'topic': '/controller/input/trajectory',
        'msg_type': 'controller_ros/Trajectory',
        'param': 'watchdog.traj_timeout_ms',
        'expected_hz': 10,
        'timeout_margin': 2.0,
        'grace_param': 'watchdog.traj_grace_ms',
        'grace_margin': 1.5,
    },
    'imu': {
        'topic': '/mobile_base/sensors/imu_data',
        'msg_type': 'sensor_msgs/Imu',
        'param': 'watchdog.imu_timeout_ms',
        'expected_hz': 100,
        'timeout_margin': 2.0,
    },
    'diagnostics': {
        'topic': '/controller/diagnostics',
        'msg_type': 'controller_ros/DiagnosticsV2',
        'param': 'diagnostics.publish_rate',
        'expected_hz': 4,
        'is_output': True,
    },
}

TF_CONFIG = {
    'source_frame': 'base_footprint',
    'target_frame': 'odom',
    'param': 'transform.timeout_ms',
    'expected_hz': 50,
    'timeout_margin': 2.0,
}


# =============================================================================
# æ•°æ®ç±»
# =============================================================================
@dataclass
class TopicStats:
    """è¯é¢˜ç»Ÿè®¡"""
    topic_name: str
    message_count: int = 0
    timestamps: List[float] = field(default_factory=list)
    
    @property
    def duration(self) -> float:
        if len(self.timestamps) < 2:
            return 0.0
        return self.timestamps[-1] - self.timestamps[0]
    
    @property
    def avg_hz(self) -> float:
        if self.duration <= 0 or self.message_count < 2:
            return 0.0
        return (self.message_count - 1) / self.duration
    
    @property
    def intervals(self) -> List[float]:
        if len(self.timestamps) < 2:
            return []
        return [self.timestamps[i+1] - self.timestamps[i] 
                for i in range(len(self.timestamps)-1)]
    
    @property
    def p95_interval_ms(self) -> float:
        intervals = self.intervals
        if not intervals:
            return 0.0
        return float(np.percentile(intervals, 95)) * 1000
    
    @property
    def max_interval_ms(self) -> float:
        intervals = self.intervals
        if not intervals:
            return 0.0
        return max(intervals) * 1000


@dataclass
class DiagnosticsStats:
    """è¯Šæ–­æ•°æ®ç»Ÿè®¡"""
    samples: List[Dict[str, Any]] = field(default_factory=list)
    
    # MPC ç»Ÿè®¡
    mpc_solve_times: List[float] = field(default_factory=list)
    mpc_no_solve_count: int = 0
    mpc_success_count: int = 0
    mpc_fail_count: int = 0
    
    # MPC å¥åº·ç›‘æ§
    mpc_consecutive_near_timeouts: List[int] = field(default_factory=list)
    mpc_degradation_warning_count: int = 0
    mpc_kkt_residuals: List[float] = field(default_factory=list)
    
    # çŠ¶æ€ç»Ÿè®¡
    state_counts: Dict[int, int] = field(default_factory=lambda: defaultdict(int))
    
    # è¶…æ—¶ç»Ÿè®¡
    odom_ages: List[float] = field(default_factory=list)
    traj_ages: List[float] = field(default_factory=list)
    imu_ages: List[float] = field(default_factory=list)
    traj_timeout_count: int = 0
    traj_grace_exceeded_count: int = 0
    odom_timeout_count: int = 0
    imu_timeout_count: int = 0
    
    # è·Ÿè¸ªè¯¯å·®
    lateral_errors: List[float] = field(default_factory=list)
    longitudinal_errors: List[float] = field(default_factory=list)
    heading_errors: List[float] = field(default_factory=list)
    prediction_errors: List[float] = field(default_factory=list)
    
    # åæ ‡å˜æ¢
    tf_fallback_durations: List[float] = field(default_factory=list)
    tf_available_count: int = 0
    tf_unavailable_count: int = 0
    
    # å®‰å…¨ç»Ÿè®¡
    safety_failed_count: int = 0
    emergency_stop_count: int = 0
    v_saturated_count: int = 0
    omega_saturated_count: int = 0
    
    # å¤‡ä»½æ§åˆ¶å™¨
    backup_active_count: int = 0


@dataclass
class TuningChange:
    """è°ƒä¼˜å˜æ›´"""
    param_path: str
    old_value: Any
    new_value: Any
    reason: str
    severity: str  # 'critical', 'warning', 'info'


# =============================================================================
# è‡ªåŠ¨è°ƒä¼˜å™¨
# =============================================================================
class AutoTuner:
    """ä¸€é”®è‡ªåŠ¨è°ƒä¼˜å™¨"""
    
    STATE_NAMES = {
        0: 'INIT', 1: 'NORMAL', 2: 'SOFT_DISABLED',
        3: 'MPC_DEGRADED', 4: 'BACKUP_ACTIVE', 5: 'STOPPING', 6: 'STOPPED',
    }
    
    def __init__(self, config_path: str = DEFAULT_CONFIG_PATH):
        self.config_path = Path(config_path)
        self.config: Dict[str, Any] = {}
        self.topic_stats: Dict[str, TopicStats] = {}
        self.tf_stats: Optional[TopicStats] = None
        self.diag_stats = DiagnosticsStats()
        self.tuning_changes: List[TuningChange] = []
        self.report_lines: List[str] = []
        
        self._load_config()
    
    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f) or {}
            self._log(f"å·²åŠ è½½é…ç½®: {self.config_path}")
        else:
            self._log(f"è­¦å‘Š: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ {self.config_path}")
    
    def _log(self, msg: str):
        """è®°å½•æ—¥å¿—"""
        print(msg)
        self.report_lines.append(msg)
    
    def _get_param(self, path: str, default: Any = None) -> Any:
        """è·å–é…ç½®å‚æ•°"""
        parts = path.split('.')
        value = self.config
        for part in parts:
            if isinstance(value, dict) and part in value:
                value = value[part]
            else:
                return default
        return value
    
    def _set_param(self, config: Dict, path: str, value: Any):
        """è®¾ç½®é…ç½®å‚æ•°"""
        parts = path.split('.')
        for part in parts[:-1]:
            if part not in config:
                config[part] = {}
            config = config[part]
        config[parts[-1]] = value

    # =========================================================================
    # æ•°æ®æ”¶é›†
    # =========================================================================
    def collect_data(self, duration_sec: float) -> bool:
        """æ”¶é›†è¯é¢˜å¸§ç‡å’Œè¯Šæ–­æ•°æ®"""
        try:
            import rospy
            from nav_msgs.msg import Odometry
            from sensor_msgs.msg import Imu
            import tf2_ros
        except ImportError:
            self._log("é”™è¯¯: éœ€è¦ ROS ç¯å¢ƒï¼Œè¯·ç¡®ä¿å·² source ROS å·¥ä½œç©ºé—´")
            return False
        
        # å°è¯•å¯¼å…¥è‡ªå®šä¹‰æ¶ˆæ¯
        try:
            from controller_ros.msg import LocalTrajectoryV4, DiagnosticsV2
            has_custom_msgs = True
            self._log("âœ“ controller_ros æ¶ˆæ¯å·²åŠ è½½")
        except ImportError as e:
            self._log(f"è­¦å‘Š: controller_ros æ¶ˆæ¯ä¸å¯ç”¨ ({e})ï¼Œéƒ¨åˆ†åŠŸèƒ½å—é™")
            has_custom_msgs = False
        
        # åˆå§‹åŒ– ROS èŠ‚ç‚¹
        try:
            rospy.init_node('auto_tuner', anonymous=True)
        except rospy.exceptions.ROSException:
            pass
        
        # è®¢é˜…å›è°ƒ
        def odom_cb(msg):
            self._add_topic_sample('/odom', rospy.Time.now().to_sec())
        
        def imu_cb(msg):
            self._add_topic_sample('/mobile_base/sensors/imu_data', rospy.Time.now().to_sec())
        
        def traj_cb(msg):
            self._add_topic_sample('/controller/input/trajectory', rospy.Time.now().to_sec())
        
        def diag_cb(msg):
            self._add_topic_sample('/controller/diagnostics', rospy.Time.now().to_sec())
            self._process_diagnostics(msg)
        
        # åˆ›å»ºè®¢é˜…è€…
        subs = []
        subs.append(rospy.Subscriber('/odom', Odometry, odom_cb))
        subs.append(rospy.Subscriber('/mobile_base/sensors/imu_data', Imu, imu_cb))
        
        if has_custom_msgs:
            subs.append(rospy.Subscriber('/controller/input/trajectory', LocalTrajectoryV4, traj_cb))
            subs.append(rospy.Subscriber('/controller/diagnostics', DiagnosticsV2, diag_cb))
        
        # TF2 ç›‘å¬
        tf_buffer = tf2_ros.Buffer()
        tf_listener = tf2_ros.TransformListener(tf_buffer)
        
        self._log(f"\nå¼€å§‹æ”¶é›†æ•°æ® ({duration_sec}ç§’)...")
        self._log("ç›‘æ§è¯é¢˜:")
        for key, cfg in TOPICS_CONFIG.items():
            self._log(f"  - {cfg['topic']}")
        self._log(f"  - TF2: {TF_CONFIG['source_frame']} â†’ {TF_CONFIG['target_frame']}")
        self._log("-" * 50)
        
        start_time = time.time()
        rate = rospy.Rate(50)
        last_progress_time = 0
        
        while not rospy.is_shutdown():
            elapsed = time.time() - start_time
            if elapsed >= duration_sec:
                break
            
            # TF é‡‡æ ·
            try:
                tf_buffer.lookup_transform(
                    TF_CONFIG['target_frame'],
                    TF_CONFIG['source_frame'],
                    rospy.Time(0),
                    rospy.Duration(0.01)
                )
                self._add_tf_sample(rospy.Time.now().to_sec())
            except:
                pass
            
            # è¿›åº¦æ˜¾ç¤º - æ¯ 10 ç§’æ›´æ–°ä¸€æ¬¡
            if elapsed - last_progress_time >= 10:
                progress = int(elapsed / duration_sec * 100)
                diag_count = len(self.diag_stats.samples)
                topic_counts = {k: v.message_count for k, v in self.topic_stats.items()}
                self._log(f"  è¿›åº¦: {progress}% ({int(elapsed)}ç§’) | è¯Šæ–­æ¶ˆæ¯: {diag_count} | è¯é¢˜: {topic_counts}")
                last_progress_time = elapsed
            
            rate.sleep()
        
        # æ¸…ç†
        for sub in subs:
            sub.unregister()
        
        self._log(f"\næ•°æ®æ”¶é›†å®Œæˆ!")
        return True
    
    def _add_topic_sample(self, topic: str, timestamp: float):
        """æ·»åŠ è¯é¢˜æ ·æœ¬"""
        if topic not in self.topic_stats:
            self.topic_stats[topic] = TopicStats(topic_name=topic)
        stats = self.topic_stats[topic]
        stats.message_count += 1
        stats.timestamps.append(timestamp)
    
    def _add_tf_sample(self, timestamp: float):
        """æ·»åŠ  TF æ ·æœ¬"""
        if self.tf_stats is None:
            self.tf_stats = TopicStats(topic_name="TF2")
        self.tf_stats.message_count += 1
        self.tf_stats.timestamps.append(timestamp)

    def _process_diagnostics(self, msg):
        """å¤„ç†è¯Šæ–­æ¶ˆæ¯"""
        sample = {}
        
        # åŸºæœ¬ä¿¡æ¯
        sample['state'] = msg.state
        self.diag_stats.state_counts[msg.state] += 1
        
        # MPC ä¿¡æ¯
        sample['mpc_solve_time_ms'] = msg.mpc_solve_time_ms
        if msg.mpc_solve_time_ms > 0:
            self.diag_stats.mpc_solve_times.append(msg.mpc_solve_time_ms)
        else:
            self.diag_stats.mpc_no_solve_count += 1
        
        # MPC æˆåŠŸ/å¤±è´¥
        if hasattr(msg, 'mpc_success'):
            if msg.mpc_success:
                self.diag_stats.mpc_success_count += 1
            else:
                self.diag_stats.mpc_fail_count += 1
        
        # MPC å¥åº·ç›‘æ§
        if hasattr(msg, 'mpc_health_consecutive_near_timeout'):
            self.diag_stats.mpc_consecutive_near_timeouts.append(msg.mpc_health_consecutive_near_timeout)
        if hasattr(msg, 'mpc_health_degradation_warning') and msg.mpc_health_degradation_warning:
            self.diag_stats.mpc_degradation_warning_count += 1
        if hasattr(msg, 'mpc_health_kkt_residual'):
            self.diag_stats.mpc_kkt_residuals.append(msg.mpc_health_kkt_residual)
        
        # å¤‡ä»½æ§åˆ¶å™¨
        if hasattr(msg, 'backup_active') and msg.backup_active:
            self.diag_stats.backup_active_count += 1
        
        # è¶…æ—¶ä¿¡æ¯ - ä½¿ç”¨é¡¶å±‚å­—æ®µ (DiagnosticsV2.msg æ ¼å¼)
        if hasattr(msg, 'timeout_last_odom_age_ms'):
            self.diag_stats.odom_ages.append(msg.timeout_last_odom_age_ms)
        if hasattr(msg, 'timeout_last_traj_age_ms'):
            self.diag_stats.traj_ages.append(msg.timeout_last_traj_age_ms)
        if hasattr(msg, 'timeout_last_imu_age_ms'):
            self.diag_stats.imu_ages.append(msg.timeout_last_imu_age_ms)
        if hasattr(msg, 'timeout_odom') and msg.timeout_odom:
            self.diag_stats.odom_timeout_count += 1
        if hasattr(msg, 'timeout_traj') and msg.timeout_traj:
            self.diag_stats.traj_timeout_count += 1
        if hasattr(msg, 'timeout_traj_grace_exceeded') and msg.timeout_traj_grace_exceeded:
            self.diag_stats.traj_grace_exceeded_count += 1
        if hasattr(msg, 'timeout_imu') and msg.timeout_imu:
            self.diag_stats.imu_timeout_count += 1
        
        # è·Ÿè¸ªè¯¯å·® - ä½¿ç”¨é¡¶å±‚å­—æ®µ
        if hasattr(msg, 'tracking_lateral_error'):
            self.diag_stats.lateral_errors.append(abs(msg.tracking_lateral_error))
        if hasattr(msg, 'tracking_longitudinal_error'):
            self.diag_stats.longitudinal_errors.append(abs(msg.tracking_longitudinal_error))
        if hasattr(msg, 'tracking_heading_error'):
            self.diag_stats.heading_errors.append(abs(msg.tracking_heading_error))
        if hasattr(msg, 'tracking_prediction_error'):
            self.diag_stats.prediction_errors.append(abs(msg.tracking_prediction_error))
        
        # åæ ‡å˜æ¢
        if hasattr(msg, 'transform_tf2_available'):
            if msg.transform_tf2_available:
                self.diag_stats.tf_available_count += 1
            else:
                self.diag_stats.tf_unavailable_count += 1
        if hasattr(msg, 'transform_fallback_duration_ms') and msg.transform_fallback_duration_ms > 0:
            self.diag_stats.tf_fallback_durations.append(msg.transform_fallback_duration_ms)
        
        # å®‰å…¨ä¿¡æ¯
        if hasattr(msg, 'safety_check_passed') and not msg.safety_check_passed:
            self.diag_stats.safety_failed_count += 1
        if hasattr(msg, 'emergency_stop') and msg.emergency_stop:
            self.diag_stats.emergency_stop_count += 1
        
        self.diag_stats.samples.append(sample)
    
    # =========================================================================
    # åˆ†æä¸è°ƒä¼˜
    # =========================================================================
    def analyze_and_tune(self) -> List[TuningChange]:
        """åˆ†ææ•°æ®å¹¶ç”Ÿæˆè°ƒä¼˜å»ºè®®"""
        self.tuning_changes = []
        
        self._log("\n" + "=" * 60)
        self._log("æ•°æ®åˆ†æ")
        self._log("=" * 60)
        
        # 1. åˆ†æè¯é¢˜å¸§ç‡
        self._analyze_topic_rates()
        
        # 2. åˆ†æè¯Šæ–­æ•°æ®
        self._analyze_diagnostics()
        
        # 3. ç”Ÿæˆè°ƒä¼˜å»ºè®®
        self._generate_tuning()
        
        return self.tuning_changes
    
    def _analyze_topic_rates(self):
        """åˆ†æè¯é¢˜å¸§ç‡"""
        self._log("\nã€è¯é¢˜å¸§ç‡åˆ†æã€‘")
        
        for key, cfg in TOPICS_CONFIG.items():
            topic = cfg['topic']
            if topic in self.topic_stats:
                stats = self.topic_stats[topic]
                expected = cfg.get('expected_hz', 10)
                status = "âœ“" if stats.avg_hz >= expected * 0.5 else "âš "
                self._log(f"  {status} {topic}")
                self._log(f"      å¸§ç‡: {stats.avg_hz:.1f} Hz (æœŸæœ› >= {expected} Hz)")
                self._log(f"      æ¶ˆæ¯æ•°: {stats.message_count}")
                self._log(f"      p95é—´éš”: {stats.p95_interval_ms:.1f} ms")
            else:
                self._log(f"  âœ— {topic} - æœªæ”¶åˆ°æ¶ˆæ¯")
        
        # TF2
        if self.tf_stats and self.tf_stats.avg_hz > 0:
            self._log(f"\n  TF2 ({TF_CONFIG['source_frame']} â†’ {TF_CONFIG['target_frame']})")
            self._log(f"      å¸§ç‡: {self.tf_stats.avg_hz:.1f} Hz")
            self._log(f"      p95é—´éš”: {self.tf_stats.p95_interval_ms:.1f} ms")

    def _analyze_diagnostics(self):
        """åˆ†æè¯Šæ–­æ•°æ®"""
        stats = self.diag_stats
        total = len(stats.samples)
        
        if total == 0:
            self._log("\nã€è¯Šæ–­æ•°æ®ã€‘æœªæ”¶åˆ°è¯Šæ–­æ¶ˆæ¯")
            return
        
        self._log(f"\nã€è¯Šæ–­æ•°æ®åˆ†æã€‘(å…± {total} æ ·æœ¬)")
        
        # çŠ¶æ€åˆ†å¸ƒ
        self._log("\n  çŠ¶æ€åˆ†å¸ƒ:")
        for state, count in sorted(stats.state_counts.items()):
            name = self.STATE_NAMES.get(state, str(state))
            pct = count / total * 100
            self._log(f"    {name}: {count} ({pct:.1f}%)")
        
        # MPC ç»Ÿè®¡
        if stats.mpc_solve_times:
            avg_solve = np.mean(stats.mpc_solve_times)
            max_solve = np.max(stats.mpc_solve_times)
            p95_solve = np.percentile(stats.mpc_solve_times, 95)
            self._log(f"\n  MPC æ±‚è§£æ—¶é—´: avg={avg_solve:.1f}ms, p95={p95_solve:.1f}ms, max={max_solve:.1f}ms")
        if stats.mpc_no_solve_count > 0:
            self._log(f"  MPC æœªæ±‚è§£æ¬¡æ•°: {stats.mpc_no_solve_count}")
        if stats.mpc_success_count + stats.mpc_fail_count > 0:
            success_rate = stats.mpc_success_count / (stats.mpc_success_count + stats.mpc_fail_count) * 100
            self._log(f"  MPC æˆåŠŸç‡: {success_rate:.1f}%")
        if stats.mpc_degradation_warning_count > 0:
            self._log(f"  MPC é™çº§è­¦å‘Š: {stats.mpc_degradation_warning_count} æ¬¡")
        if stats.backup_active_count > 0:
            pct = stats.backup_active_count / total * 100
            self._log(f"  å¤‡ä»½æ§åˆ¶å™¨æ¿€æ´»: {stats.backup_active_count} ({pct:.1f}%)")
        
        # è¶…æ—¶ç»Ÿè®¡
        if stats.traj_ages:
            avg_age = np.mean(stats.traj_ages)
            max_age = np.max(stats.traj_ages)
            p95_age = np.percentile(stats.traj_ages, 95)
            self._log(f"\n  è½¨è¿¹å»¶è¿Ÿ: avg={avg_age:.1f}ms, p95={p95_age:.1f}ms, max={max_age:.1f}ms")
        if stats.traj_timeout_count > 0:
            self._log(f"  è½¨è¿¹è¶…æ—¶æ¬¡æ•°: {stats.traj_timeout_count}")
        if stats.traj_grace_exceeded_count > 0:
            self._log(f"  å®½é™æœŸè¶…æ—¶æ¬¡æ•°: {stats.traj_grace_exceeded_count}")
        if stats.odom_timeout_count > 0:
            self._log(f"  é‡Œç¨‹è®¡è¶…æ—¶æ¬¡æ•°: {stats.odom_timeout_count}")
        
        # åæ ‡å˜æ¢
        if stats.tf_fallback_durations:
            avg_fallback = np.mean(stats.tf_fallback_durations)
            max_fallback = np.max(stats.tf_fallback_durations)
            self._log(f"\n  TF é™çº§æŒç»­æ—¶é—´: avg={avg_fallback:.1f}ms, max={max_fallback:.1f}ms")
        if stats.tf_unavailable_count > 0:
            pct = stats.tf_unavailable_count / total * 100
            self._log(f"  TF ä¸å¯ç”¨: {stats.tf_unavailable_count} ({pct:.1f}%)")
        
        # è·Ÿè¸ªè¯¯å·®
        if stats.lateral_errors:
            self._log(f"\n  è·Ÿè¸ªè¯¯å·®:")
            self._log(f"    æ¨ªå‘: avg={np.mean(stats.lateral_errors)*100:.1f}cm, max={np.max(stats.lateral_errors)*100:.1f}cm")
            self._log(f"    çºµå‘: avg={np.mean(stats.longitudinal_errors)*100:.1f}cm, max={np.max(stats.longitudinal_errors)*100:.1f}cm")
            self._log(f"    èˆªå‘: avg={np.degrees(np.mean(stats.heading_errors)):.1f}Â°, max={np.degrees(np.max(stats.heading_errors)):.1f}Â°")
        if stats.prediction_errors:
            self._log(f"    é¢„æµ‹: avg={np.mean(stats.prediction_errors)*100:.1f}cm")
        
        # å®‰å…¨ç»Ÿè®¡
        if stats.safety_failed_count > 0:
            pct = stats.safety_failed_count / total * 100
            self._log(f"\n  å®‰å…¨æ£€æŸ¥å¤±è´¥: {stats.safety_failed_count} ({pct:.1f}%)")
        if stats.emergency_stop_count > 0:
            self._log(f"  ç´§æ€¥åœæ­¢: {stats.emergency_stop_count} æ¬¡")
    
    def _generate_tuning(self):
        """ç”Ÿæˆè°ƒä¼˜å»ºè®®"""
        self._log("\n" + "=" * 60)
        self._log("è°ƒä¼˜å»ºè®®")
        self._log("=" * 60)
        
        # 1. åŸºäºè¯é¢˜å¸§ç‡è°ƒä¼˜è¶…æ—¶å‚æ•°
        self._tune_timeouts()
        
        # 2. åŸºäºè¯Šæ–­æ•°æ®è°ƒä¼˜ MPC å‚æ•°
        self._tune_mpc()
        
        # 3. åŸºäºè·Ÿè¸ªè¯¯å·®è°ƒä¼˜æƒé‡
        self._tune_weights()
        
        # 4. åŸºäºè·Ÿè¸ªè¯¯å·®è°ƒä¼˜é˜ˆå€¼
        self._tune_tracking_thresholds()
        
        # 5. åŸºäº TF é™çº§è°ƒä¼˜åæ ‡å˜æ¢å‚æ•°
        self._tune_transform()
        
        # 6. åŸºäºçŠ¶æ€æœºç»Ÿè®¡è°ƒä¼˜çŠ¶æ€æœºå‚æ•°
        self._tune_state_machine()
        
        # 7. ä½é¢‘è½¨è¿¹ä¸“é¡¹ä¼˜åŒ–
        self._tune_low_frequency_trajectory()
        
        if not self.tuning_changes:
            self._log("\nâœ… å½“å‰é…ç½®å·²ç»æ˜¯æœ€ä¼˜ï¼Œæ— éœ€è°ƒæ•´")

    def _tune_timeouts(self):
        """è°ƒä¼˜è¶…æ—¶å‚æ•°"""
        # Odom è¶…æ—¶
        odom_topic = '/odom'
        if odom_topic in self.topic_stats:
            stats = self.topic_stats[odom_topic]
            if stats.avg_hz > 0:
                cfg = TOPICS_CONFIG['odom']
                current = self._get_param(cfg['param'], 500)
                # å»ºè®®å€¼ = max(p95é—´éš”, å¹³å‡å‘¨æœŸ) * margin
                period_ms = 1000.0 / stats.avg_hz
                suggested = int(max(stats.p95_interval_ms, period_ms) * cfg['timeout_margin'])
                suggested = max(suggested, 100)  # æœ€å° 100ms
                
                if current < suggested * 0.8:
                    self._add_change(cfg['param'], current, suggested,
                        f"odom å¸§ç‡ {stats.avg_hz:.1f}Hz, p95é—´éš” {stats.p95_interval_ms:.0f}ms",
                        'warning')
        
        # è½¨è¿¹è¶…æ—¶
        traj_topic = '/controller/input/trajectory'
        if traj_topic in self.topic_stats:
            stats = self.topic_stats[traj_topic]
            if stats.avg_hz > 0:
                cfg = TOPICS_CONFIG['trajectory']
                
                # timeout
                current_timeout = self._get_param(cfg['param'], 1000)
                period_ms = 1000.0 / stats.avg_hz
                suggested_timeout = int(max(stats.p95_interval_ms, period_ms) * cfg['timeout_margin'])
                suggested_timeout = max(suggested_timeout, 500)  # æœ€å° 500ms
                
                if current_timeout < suggested_timeout * 0.8:
                    self._add_change(cfg['param'], current_timeout, suggested_timeout,
                        f"è½¨è¿¹å¸§ç‡ {stats.avg_hz:.1f}Hz, p95é—´éš” {stats.p95_interval_ms:.0f}ms",
                        'warning')
                
                # grace
                current_grace = self._get_param(cfg['grace_param'], 600)
                suggested_grace = int(max(stats.p95_interval_ms, period_ms) * cfg['grace_margin'])
                suggested_grace = max(suggested_grace, 300)  # æœ€å° 300ms
                
                if current_grace < suggested_grace * 0.8:
                    self._add_change(cfg['grace_param'], current_grace, suggested_grace,
                        f"è½¨è¿¹å¸§ç‡ {stats.avg_hz:.1f}Hz, å®½é™æœŸéœ€è¦æ›´é•¿",
                        'warning')
        
        # åŸºäºè¯Šæ–­æ•°æ®çš„è¶…æ—¶è°ƒä¼˜
        stats = self.diag_stats
        total = len(stats.samples)
        
        if total > 0:
            # å¦‚æœæœ‰è½¨è¿¹è¶…æ—¶ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
            if stats.traj_timeout_count > 0:
                timeout_rate = stats.traj_timeout_count / total * 100
                if timeout_rate > 1:  # è¶…è¿‡ 1% è¶…æ—¶ç‡
                    current = self._get_param('watchdog.traj_timeout_ms', 1000)
                    if stats.traj_ages:
                        p99_age = np.percentile(stats.traj_ages, 99)
                        suggested = int(p99_age * 1.5)
                        suggested = max(suggested, current + 500)
                        self._add_change('watchdog.traj_timeout_ms', current, suggested,
                            f"è½¨è¿¹è¶…æ—¶ç‡ {timeout_rate:.1f}%, p99å»¶è¿Ÿ {p99_age:.0f}ms",
                            'critical')
            
            # å¦‚æœæœ‰å®½é™æœŸè¶…æ—¶ï¼Œå¢åŠ å®½é™æœŸ
            if stats.traj_grace_exceeded_count > 0:
                grace_rate = stats.traj_grace_exceeded_count / total * 100
                if grace_rate > 1:
                    current = self._get_param('watchdog.traj_grace_ms', 600)
                    suggested = int(current * 1.5)
                    self._add_change('watchdog.traj_grace_ms', current, suggested,
                        f"å®½é™æœŸè¶…æ—¶ç‡ {grace_rate:.1f}%",
                        'warning')
        
        # TF è¶…æ—¶
        if self.tf_stats and self.tf_stats.avg_hz > 0:
            current = self._get_param(TF_CONFIG['param'], 50)
            period_ms = 1000.0 / self.tf_stats.avg_hz
            suggested = int(max(self.tf_stats.p95_interval_ms, period_ms) * TF_CONFIG['timeout_margin'])
            suggested = max(suggested, 30)  # æœ€å° 30ms
            
            if current < suggested * 0.8:
                self._add_change(TF_CONFIG['param'], current, suggested,
                    f"TF å¸§ç‡ {self.tf_stats.avg_hz:.1f}Hz",
                    'warning')

    def _tune_mpc(self):
        """è°ƒä¼˜ MPC å‚æ•°"""
        stats = self.diag_stats
        total = len(stats.samples)
        
        if total == 0:
            return
        
        # MPC æ±‚è§£æ—¶é—´åˆ†æ
        if stats.mpc_solve_times:
            avg_solve = np.mean(stats.mpc_solve_times)
            p95_solve = np.percentile(stats.mpc_solve_times, 95)
            p99_solve = np.percentile(stats.mpc_solve_times, 99)
            
            # è­¦å‘Šé˜ˆå€¼
            current_warning = self._get_param('mpc.health_monitor.time_warning_thresh_ms', 20)
            if p95_solve > current_warning * 0.8:
                suggested = int(p95_solve * 1.5)
                self._add_change('mpc.health_monitor.time_warning_thresh_ms', 
                    current_warning, suggested,
                    f"MPC p95æ±‚è§£æ—¶é—´ {p95_solve:.1f}ms æ¥è¿‘è­¦å‘Šé˜ˆå€¼",
                    'info')
            
            # ä¸´ç•Œé˜ˆå€¼
            current_critical = self._get_param('mpc.health_monitor.time_critical_thresh_ms', 40)
            if p99_solve > current_critical * 0.8:
                suggested = int(p99_solve * 1.5)
                self._add_change('mpc.health_monitor.time_critical_thresh_ms',
                    current_critical, suggested,
                    f"MPC p99æ±‚è§£æ—¶é—´ {p99_solve:.1f}ms æ¥è¿‘ä¸´ç•Œé˜ˆå€¼",
                    'warning')
        
        # MPC è¿ç»­è¶…æ—¶åˆ†æ
        if stats.mpc_consecutive_near_timeouts:
            max_consecutive = max(stats.mpc_consecutive_near_timeouts)
            current_limit = self._get_param('mpc.health_monitor.consecutive_warning_limit', 10)
            if max_consecutive > current_limit * 0.8:
                suggested = int(max_consecutive * 1.5)
                self._add_change('mpc.health_monitor.consecutive_warning_limit',
                    current_limit, suggested,
                    f"è¿ç»­æ¥è¿‘è¶…æ—¶æœ€å¤§å€¼ {max_consecutive} æ¥è¿‘é™åˆ¶",
                    'info')
        
        # MPC æˆåŠŸç‡åˆ†æ - è°ƒä¼˜ horizon
        if stats.mpc_success_count + stats.mpc_fail_count > 0:
            success_rate = stats.mpc_success_count / (stats.mpc_success_count + stats.mpc_fail_count)
            if success_rate < 0.9:  # æˆåŠŸç‡ä½äº 90%
                current_horizon = self._get_param('mpc.horizon', 7)
                if current_horizon > 4:
                    suggested = current_horizon - 1
                    self._add_change('mpc.horizon', current_horizon, suggested,
                        f"MPC æˆåŠŸç‡ {success_rate*100:.1f}% è¾ƒä½ï¼Œå‡å°é¢„æµ‹æ—¶åŸŸ",
                        'warning')
        
        # MPC é™çº§ç‡åˆ†æ
        degraded_count = stats.state_counts.get(3, 0)  # MPC_DEGRADED
        if degraded_count > 0:
            degraded_rate = degraded_count / total * 100
            if degraded_rate > 5:
                # å¢åŠ æ¢å¤å®¹é”™
                current = self._get_param('safety.state_machine.mpc_recovery_tolerance', 1)
                suggested = min(current + 1, 3)
                if suggested > current:
                    self._add_change('safety.state_machine.mpc_recovery_tolerance',
                        current, suggested,
                        f"MPC é™çº§ç‡ {degraded_rate:.1f}%ï¼Œå¢åŠ æ¢å¤å®¹é”™",
                        'warning')
    
    def _tune_weights(self):
        """è°ƒä¼˜ MPC æƒé‡"""
        stats = self.diag_stats
        
        if not stats.lateral_errors or not stats.longitudinal_errors:
            return
        
        avg_lateral = np.mean(stats.lateral_errors)
        avg_longitudinal = np.mean(stats.longitudinal_errors)
        avg_heading = np.mean(stats.heading_errors) if stats.heading_errors else 0
        
        # çºµå‘è¯¯å·®è¿‡å¤§ï¼Œå¢åŠ é€Ÿåº¦æƒé‡
        if avg_longitudinal > 0.5:  # > 50cm
            current = self._get_param('mpc.weights.velocity', 6.0)
            # è¯¯å·®è¶Šå¤§ï¼Œæƒé‡å¢åŠ è¶Šå¤š
            factor = min(avg_longitudinal / 0.3, 1.5)  # æœ€å¤šå¢åŠ  50%
            suggested = round(current * factor, 1)
            if suggested > current:
                self._add_change('mpc.weights.velocity', current, suggested,
                    f"çºµå‘è¯¯å·® avg={avg_longitudinal*100:.1f}cm è¿‡å¤§",
                    'warning')
        
        # æ¨ªå‘è¯¯å·®è¿‡å¤§ï¼Œå¢åŠ ä½ç½®æƒé‡
        if avg_lateral > 0.15:  # > 15cm
            current = self._get_param('mpc.weights.position', 15.0)
            factor = min(avg_lateral / 0.1, 1.3)
            suggested = round(current * factor, 1)
            if suggested > current:
                self._add_change('mpc.weights.position', current, suggested,
                    f"æ¨ªå‘è¯¯å·® avg={avg_lateral*100:.1f}cm è¿‡å¤§",
                    'warning')
        
        # èˆªå‘è¯¯å·®è¿‡å¤§ï¼Œå¢åŠ èˆªå‘æƒé‡
        if avg_heading > 0.2:  # > ~11Â°
            current = self._get_param('mpc.weights.heading', 8.0)
            factor = min(avg_heading / 0.15, 1.3)
            suggested = round(current * factor, 1)
            if suggested > current:
                self._add_change('mpc.weights.heading', current, suggested,
                    f"èˆªå‘è¯¯å·® avg={np.degrees(avg_heading):.1f}Â° è¿‡å¤§",
                    'warning')
    
    def _add_change(self, param: str, old_val: Any, new_val: Any, reason: str, severity: str):
        """æ·»åŠ è°ƒä¼˜å˜æ›´"""
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå‚æ•°çš„å˜æ›´
        for change in self.tuning_changes:
            if change.param_path == param:
                # ä¿ç•™æ›´æ¿€è¿›çš„å˜æ›´
                if severity == 'critical' or new_val > change.new_value:
                    change.new_value = new_val
                    change.reason = reason
                    change.severity = severity
                return
        
        change = TuningChange(param, old_val, new_val, reason, severity)
        self.tuning_changes.append(change)
        
        severity_icon = {'critical': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}
        self._log(f"\n{severity_icon.get(severity, 'â€¢')} {param}")
        self._log(f"    å½“å‰å€¼: {old_val} â†’ å»ºè®®å€¼: {new_val}")
        self._log(f"    åŸå› : {reason}")
    
    def _tune_tracking_thresholds(self):
        """è°ƒä¼˜è·Ÿè¸ªè¯¯å·®é˜ˆå€¼"""
        stats = self.diag_stats
        
        if not stats.lateral_errors:
            return
        
        # æ¨ªå‘è¯¯å·®é˜ˆå€¼
        p95_lateral = np.percentile(stats.lateral_errors, 95)
        current_lateral_thresh = self._get_param('tracking.lateral_thresh', 0.25)
        if p95_lateral > current_lateral_thresh * 0.8:
            suggested = round(p95_lateral * 1.3, 2)
            self._add_change('tracking.lateral_thresh', current_lateral_thresh, suggested,
                f"æ¨ªå‘è¯¯å·® p95={p95_lateral*100:.1f}cm æ¥è¿‘é˜ˆå€¼",
                'info')
        
        # çºµå‘è¯¯å·®é˜ˆå€¼
        if stats.longitudinal_errors:
            p95_longitudinal = np.percentile(stats.longitudinal_errors, 95)
            current_longitudinal_thresh = self._get_param('tracking.longitudinal_thresh', 0.6)
            if p95_longitudinal > current_longitudinal_thresh * 0.8:
                suggested = round(p95_longitudinal * 1.3, 2)
                self._add_change('tracking.longitudinal_thresh', current_longitudinal_thresh, suggested,
                    f"çºµå‘è¯¯å·® p95={p95_longitudinal*100:.1f}cm æ¥è¿‘é˜ˆå€¼",
                    'info')
        
        # èˆªå‘è¯¯å·®é˜ˆå€¼
        if stats.heading_errors:
            p95_heading = np.percentile(stats.heading_errors, 95)
            current_heading_thresh = self._get_param('tracking.heading_thresh', 0.5)
            if p95_heading > current_heading_thresh * 0.8:
                suggested = round(p95_heading * 1.3, 2)
                self._add_change('tracking.heading_thresh', current_heading_thresh, suggested,
                    f"èˆªå‘è¯¯å·® p95={np.degrees(p95_heading):.1f}Â° æ¥è¿‘é˜ˆå€¼",
                    'info')
        
        # é¢„æµ‹è¯¯å·®é˜ˆå€¼
        if stats.prediction_errors:
            p95_prediction = np.percentile(stats.prediction_errors, 95)
            current_prediction_thresh = self._get_param('tracking.prediction_thresh', 0.5)
            if p95_prediction > current_prediction_thresh * 0.8:
                suggested = round(p95_prediction * 1.3, 2)
                self._add_change('tracking.prediction_thresh', current_prediction_thresh, suggested,
                    f"é¢„æµ‹è¯¯å·® p95={p95_prediction*100:.1f}cm æ¥è¿‘é˜ˆå€¼",
                    'info')
    
    def _tune_transform(self):
        """è°ƒä¼˜åæ ‡å˜æ¢å‚æ•°"""
        stats = self.diag_stats
        
        if not stats.tf_fallback_durations:
            return
        
        p95_fallback = np.percentile(stats.tf_fallback_durations, 95)
        max_fallback = np.max(stats.tf_fallback_durations)
        
        # é™çº§è­¦å‘Šé˜ˆå€¼
        current_limit = self._get_param('transform.fallback_duration_limit_ms', 500)
        if p95_fallback > current_limit * 0.8:
            suggested = int(p95_fallback * 1.5)
            self._add_change('transform.fallback_duration_limit_ms', current_limit, suggested,
                f"TF é™çº§æŒç»­æ—¶é—´ p95={p95_fallback:.0f}ms æ¥è¿‘è­¦å‘Šé˜ˆå€¼",
                'warning')
        
        # é™çº§ä¸´ç•Œé˜ˆå€¼
        current_critical = self._get_param('transform.fallback_critical_limit_ms', 1000)
        if max_fallback > current_critical * 0.8:
            suggested = int(max_fallback * 1.5)
            self._add_change('transform.fallback_critical_limit_ms', current_critical, suggested,
                f"TF é™çº§æŒç»­æ—¶é—´ max={max_fallback:.0f}ms æ¥è¿‘ä¸´ç•Œé˜ˆå€¼",
                'warning')
    
    def _tune_state_machine(self):
        """è°ƒä¼˜çŠ¶æ€æœºå‚æ•°"""
        stats = self.diag_stats
        total = len(stats.samples)
        
        if total == 0:
            return
        
        # MPC å¤±è´¥ç‡åˆ†æ
        if stats.mpc_success_count + stats.mpc_fail_count > 0:
            fail_rate = stats.mpc_fail_count / (stats.mpc_success_count + stats.mpc_fail_count)
            current_thresh = self._get_param('safety.state_machine.mpc_fail_ratio_thresh', 0.5)
            
            # å¦‚æœå®é™…å¤±è´¥ç‡æ¥è¿‘é˜ˆå€¼ï¼Œé€‚å½“æ”¾å®½
            if fail_rate > current_thresh * 0.7 and fail_rate < current_thresh:
                suggested = round(fail_rate * 1.3, 2)
                suggested = min(suggested, 0.7)  # ä¸è¶…è¿‡ 70%
                self._add_change('safety.state_machine.mpc_fail_ratio_thresh',
                    current_thresh, suggested,
                    f"MPC å¤±è´¥ç‡ {fail_rate*100:.1f}% æ¥è¿‘é˜ˆå€¼",
                    'info')
        
        # å¤‡ä»½æ§åˆ¶å™¨æ¿€æ´»ç‡åˆ†æ
        backup_count = stats.state_counts.get(4, 0)  # BACKUP_ACTIVE
        if backup_count > 0:
            backup_rate = backup_count / total * 100
            if backup_rate > 10:  # å¤‡ä»½æ¿€æ´»ç‡è¶…è¿‡ 10%
                # å¯èƒ½éœ€è¦è°ƒæ•´ MPC æ¢å¤é˜ˆå€¼
                current_recovery = self._get_param('safety.state_machine.mpc_recovery_thresh', 5)
                suggested = max(current_recovery - 1, 3)
                if suggested < current_recovery:
                    self._add_change('safety.state_machine.mpc_recovery_thresh',
                        current_recovery, suggested,
                        f"å¤‡ä»½æ§åˆ¶å™¨æ¿€æ´»ç‡ {backup_rate:.1f}% è¿‡é«˜ï¼Œé™ä½æ¢å¤é˜ˆå€¼",
                        'warning')

    def _tune_low_frequency_trajectory(self):
        """ä½é¢‘è½¨è¿¹ä¸“é¡¹ä¼˜åŒ–
        
        å½“è½¨è¿¹é¢‘ç‡ä½äº 5Hz æ—¶ï¼Œè‡ªåŠ¨è°ƒä¼˜ä»¥ä¸‹å‚æ•°:
        - consistency.temporal_window_size: å‡å°‘å†å²çª—å£ï¼ŒåŠ å¿«å“åº”
        - backup.lookahead_dist: å¢åŠ å‰ç»è·ç¦»è¡¥å¿å»¶è¿Ÿ
        - backup.min_lookahead: é…åˆå¢åŠ çš„å‰ç»è·ç¦»
        - backup.max_lookahead: å…è®¸æ›´å¤§åŠ¨æ€å‰ç»
        - safety.state_machine.mpc_fail_thresh: æ”¾å®½å¤±è´¥é˜ˆå€¼
        """
        # æ£€æŸ¥è½¨è¿¹é¢‘ç‡
        traj_topic = '/controller/input/trajectory'
        if traj_topic not in self.topic_stats:
            return
        
        traj_stats = self.topic_stats[traj_topic]
        traj_hz = traj_stats.avg_hz
        
        # åªæœ‰å½“è½¨è¿¹é¢‘ç‡ä½äº 5Hz æ—¶æ‰è¿›è¡Œä½é¢‘ä¼˜åŒ–
        LOW_FREQ_THRESHOLD = 5.0
        if traj_hz <= 0 or traj_hz >= LOW_FREQ_THRESHOLD:
            return
        
        self._log(f"\nã€ä½é¢‘è½¨è¿¹ä¸“é¡¹ä¼˜åŒ–ã€‘(è½¨è¿¹é¢‘ç‡: {traj_hz:.1f}Hz < {LOW_FREQ_THRESHOLD}Hz)")
        
        # è®¡ç®—è½¨è¿¹å‘¨æœŸ (ms)
        traj_period_ms = 1000.0 / traj_hz
        
        # 1. ä¸€è‡´æ€§æ£€æŸ¥æ—¶åºçª—å£
        # ä½é¢‘è½¨è¿¹ä¸‹ï¼Œå‡å°‘å†å²çª—å£ä»¥åŠ å¿«å¯¹è½¨è¿¹å˜åŒ–çš„å“åº”
        # ç›®æ ‡: ä¿æŒçº¦ 2-3 ç§’çš„å†å²æ•°æ®
        current_window = self._get_param('consistency.temporal_window_size', 10)
        target_history_sec = 2.5  # ç›®æ ‡å†å²æ—¶é—´
        suggested_window = max(int(target_history_sec * traj_hz), 4)  # æœ€å° 4 ä¸ªæ ·æœ¬
        
        if current_window > suggested_window * 1.3:
            self._add_change('consistency.temporal_window_size', current_window, suggested_window,
                f"ä½é¢‘è½¨è¿¹({traj_hz:.1f}Hz)ä¸‹å‡å°‘å†å²çª—å£åˆ°~{target_history_sec}ç§’",
                'info')
        
        # 2. å¤‡ä»½æ§åˆ¶å™¨å‰ç»è·ç¦»
        # ä½é¢‘è½¨è¿¹ä¸‹ï¼Œéœ€è¦æ›´å¤§çš„å‰ç»è·ç¦»æ¥è¡¥å¿è½¨è¿¹æ›´æ–°å»¶è¿Ÿ
        # å‰ç»è·ç¦»åº”è¯¥èƒ½è¦†ç›–è‡³å°‘ 1-2 ä¸ªè½¨è¿¹å‘¨æœŸçš„è¡Œé©¶è·ç¦»
        current_lookahead = self._get_param('backup.lookahead_dist', 0.5)
        v_max = self._get_param('constraints.v_max', 0.5)
        
        # è®¡ç®—å»ºè®®çš„å‰ç»è·ç¦»: è‡³å°‘è¦†ç›– 1.5 ä¸ªè½¨è¿¹å‘¨æœŸ
        min_lookahead_for_freq = v_max * (traj_period_ms / 1000.0) * 1.5
        suggested_lookahead = max(current_lookahead, round(min_lookahead_for_freq + 0.2, 1))
        suggested_lookahead = min(suggested_lookahead, 1.5)  # ä¸è¶…è¿‡ 1.5m
        
        if suggested_lookahead > current_lookahead * 1.2:
            self._add_change('backup.lookahead_dist', current_lookahead, suggested_lookahead,
                f"ä½é¢‘è½¨è¿¹({traj_hz:.1f}Hz)éœ€è¦æ›´å¤§å‰ç»è·ç¦»è¡¥å¿å»¶è¿Ÿ",
                'info')
            
            # åŒæ­¥è°ƒæ•´ min_lookahead å’Œ max_lookahead
            current_min = self._get_param('backup.min_lookahead', 0.3)
            suggested_min = round(suggested_lookahead * 0.6, 1)
            if suggested_min > current_min:
                self._add_change('backup.min_lookahead', current_min, suggested_min,
                    f"é…åˆå¢åŠ çš„å‰ç»è·ç¦»",
                    'info')
            
            current_max = self._get_param('backup.max_lookahead', 1.5)
            suggested_max = round(suggested_lookahead * 2.5, 1)
            suggested_max = min(suggested_max, 3.0)  # ä¸è¶…è¿‡ 3m
            if suggested_max > current_max:
                self._add_change('backup.max_lookahead', current_max, suggested_max,
                    f"å…è®¸æ›´å¤§çš„åŠ¨æ€å‰ç»èŒƒå›´",
                    'info')
        
        # 3. MPC å¤±è´¥é˜ˆå€¼
        # ä½é¢‘è½¨è¿¹ä¸‹ï¼ŒMPC å¯èƒ½æ›´å®¹æ˜“å› ä¸ºè½¨è¿¹ç‚¹ä¸è¶³è€Œ"å¤±è´¥"
        # é€‚å½“æ”¾å®½å¤±è´¥é˜ˆå€¼ï¼Œå‡å°‘ä¸å¿…è¦çš„å¤‡ä»½æ§åˆ¶å™¨åˆ‡æ¢
        stats = self.diag_stats
        total = len(stats.samples)
        
        if total > 0:
            # æ£€æŸ¥ MPC é™çº§å’Œå¤‡ä»½æ¿€æ´»æƒ…å†µ
            degraded_count = stats.state_counts.get(3, 0)  # MPC_DEGRADED
            backup_count = stats.state_counts.get(4, 0)  # BACKUP_ACTIVE
            
            # å¦‚æœé™çº§æˆ–å¤‡ä»½æ¿€æ´»ç‡è¾ƒé«˜ï¼Œæ”¾å®½å¤±è´¥é˜ˆå€¼
            problem_rate = (degraded_count + backup_count) / total * 100
            
            if problem_rate > 3:  # è¶…è¿‡ 3% çš„æ—¶é—´å¤„äºéæ­£å¸¸çŠ¶æ€
                current_fail_thresh = self._get_param('safety.state_machine.mpc_fail_thresh', 3)
                suggested_fail_thresh = min(current_fail_thresh + 1, 5)  # æœ€å¤šå¢åŠ åˆ° 5
                
                if suggested_fail_thresh > current_fail_thresh:
                    self._add_change('safety.state_machine.mpc_fail_thresh',
                        current_fail_thresh, suggested_fail_thresh,
                        f"ä½é¢‘è½¨è¿¹ä¸‹æ”¾å®½MPCå¤±è´¥é˜ˆå€¼(é™çº§+å¤‡ä»½ç‡{problem_rate:.1f}%)",
                        'info')
        
        # 4. è½¨è¿¹ä½é€Ÿé˜ˆå€¼
        # ä½é¢‘è½¨è¿¹ä¸‹ï¼Œå¯èƒ½éœ€è¦æ›´ä½çš„ä½é€Ÿé˜ˆå€¼æ¥é¿å…è¯¯åˆ¤
        current_low_speed = self._get_param('trajectory.low_speed_thresh', 0.05)
        if traj_hz < 3:  # éå¸¸ä½çš„é¢‘ç‡
            suggested_low_speed = 0.03
            if current_low_speed > suggested_low_speed:
                self._add_change('trajectory.low_speed_thresh', current_low_speed, suggested_low_speed,
                    f"æä½é¢‘è½¨è¿¹({traj_hz:.1f}Hz)ä¸‹é™ä½ä½é€Ÿé˜ˆå€¼",
                    'info')

    # =========================================================================
    # è¾“å‡º
    # =========================================================================
    def generate_tuned_config(self, output_path: str = None) -> str:
        """ç”Ÿæˆè°ƒä¼˜åçš„é…ç½®æ–‡ä»¶"""
        if not self.tuning_changes:
            self._log("\næ— éœ€ç”Ÿæˆæ–°é…ç½®ï¼Œå½“å‰é…ç½®å·²æ˜¯æœ€ä¼˜")
            return None
        
        # å¤åˆ¶åŸé…ç½®
        tuned_config = copy.deepcopy(self.config)
        
        # åº”ç”¨å˜æ›´
        for change in self.tuning_changes:
            self._set_param(tuned_config, change.param_path, change.new_value)
        
        # æ›´æ–°è°ƒä¼˜è®°å½•
        now = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_path is None:
            output_dir = Path(DEFAULT_OUTPUT_DIR)
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / "tuned_turtlebot1.yaml"
        else:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆ YAML å†…å®¹
        yaml_content = self._generate_yaml_with_comments(tuned_config, now)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(yaml_content)
        
        self._log(f"\nâœ… è°ƒä¼˜é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)
    
    def _generate_yaml_with_comments(self, config: Dict, timestamp: str) -> str:
        """ç”Ÿæˆå¸¦æ³¨é‡Šçš„ YAML"""
        # è¯»å–åŸæ–‡ä»¶ä½œä¸ºæ¨¡æ¿
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
        else:
            original_content = ""
        
        # ç”Ÿæˆè°ƒä¼˜è®°å½•å¤´
        header = f"""# =============================================================================
# è‡ªåŠ¨è°ƒä¼˜é…ç½® - ç”± auto_tune.py ç”Ÿæˆ
# ç”Ÿæˆæ—¶é—´: {timestamp}
# =============================================================================
# 
# è°ƒä¼˜å˜æ›´:
"""
        for change in self.tuning_changes:
            header += f"#   - {change.param_path}: {change.old_value} â†’ {change.new_value}\n"
            header += f"#     åŸå› : {change.reason}\n"
        
        header += "#\n# =============================================================================\n\n"
        
        # ç”Ÿæˆ YAML
        yaml_str = yaml.dump(config, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        return header + yaml_str
    
    def apply_to_config(self) -> bool:
        """ç›´æ¥åº”ç”¨è°ƒä¼˜åˆ°åŸé…ç½®æ–‡ä»¶"""
        if not self.tuning_changes:
            self._log("\næ— éœ€åº”ç”¨ï¼Œå½“å‰é…ç½®å·²æ˜¯æœ€ä¼˜")
            return False
        
        # å¤‡ä»½åŸæ–‡ä»¶
        backup_path = self.config_path.with_suffix('.yaml.bak')
        shutil.copy(self.config_path, backup_path)
        self._log(f"\nå·²å¤‡ä»½åŸé…ç½®åˆ°: {backup_path}")
        
        # è¯»å–åŸæ–‡ä»¶
        with open(self.config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # é€ä¸ªæ›¿æ¢å‚æ•°å€¼
        for change in self.tuning_changes:
            content = self._replace_param_in_yaml(content, change)
        
        # å†™å›æ–‡ä»¶
        with open(self.config_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self._log(f"âœ… è°ƒä¼˜å·²åº”ç”¨åˆ°: {self.config_path}")
        return True
    
    def _replace_param_in_yaml(self, content: str, change: TuningChange) -> str:
        """åœ¨ YAML å†…å®¹ä¸­æ›¿æ¢å‚æ•°å€¼"""
        import re
        
        # è·å–å‚æ•°å (æœ€åä¸€éƒ¨åˆ†)
        param_name = change.param_path.split('.')[-1]
        
        # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å‚æ•°è¡Œ
        # åŒ¹é…: param_name: value æˆ– param_name: value # comment
        pattern = rf'(\s*{param_name}:\s*)({re.escape(str(change.old_value))})(\s*(?:#.*)?$)'
        
        def replacer(match):
            return f"{match.group(1)}{change.new_value}{match.group(3)}"
        
        new_content = re.sub(pattern, replacer, content, flags=re.MULTILINE)
        
        return new_content
    
    def save_report(self, output_path: str = None):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        if output_path is None:
            output_dir = Path(DEFAULT_OUTPUT_DIR)
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / "auto_tune_report.txt"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(self.report_lines))
        
        self._log(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================
def main():
    parser = argparse.ArgumentParser(
        description='ä¸€é”®è‡ªåŠ¨è°ƒä¼˜å·¥å…· - æ”¶é›†æ•°æ®ã€åˆ†æã€ç”Ÿæˆè°ƒä¼˜é…ç½®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ”¶é›† 30 ç§’æ•°æ®å¹¶ç”Ÿæˆè°ƒä¼˜é…ç½®
  python -m tools.tuning.auto_tune --duration 30
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python -m tools.tuning.auto_tune --duration 30 --output my_tuned.yaml
  
  # ç›´æ¥åº”ç”¨åˆ°é…ç½®æ–‡ä»¶
  python -m tools.tuning.auto_tune --duration 30 --apply
  
  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
  python -m tools.tuning.auto_tune --config path/to/config.yaml --duration 30
"""
    )
    parser.add_argument('--duration', type=float, default=30,
                        help='æ•°æ®æ”¶é›†æŒç»­æ—¶é—´(ç§’)ï¼Œé»˜è®¤ 30 ç§’')
    parser.add_argument('--config', type=str, default=DEFAULT_CONFIG_PATH,
                        help=f'é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ {DEFAULT_CONFIG_PATH}')
    parser.add_argument('--output', type=str,
                        help='è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ tuning_output/tuned_turtlebot1.yaml')
    parser.add_argument('--apply', action='store_true',
                        help='ç›´æ¥åº”ç”¨è°ƒä¼˜åˆ°åŸé…ç½®æ–‡ä»¶')
    parser.add_argument('--no-report', action='store_true',
                        help='ä¸ä¿å­˜åˆ†ææŠ¥å‘Š')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ä¸€é”®è‡ªåŠ¨è°ƒä¼˜å·¥å…· v1.0")
    print("=" * 60)
    
    # åˆ›å»ºè°ƒä¼˜å™¨
    tuner = AutoTuner(args.config)
    
    # æ”¶é›†æ•°æ®
    if not tuner.collect_data(args.duration):
        print("\nâŒ æ•°æ®æ”¶é›†å¤±è´¥")
        sys.exit(1)
    
    # åˆ†æå¹¶ç”Ÿæˆè°ƒä¼˜å»ºè®®
    changes = tuner.analyze_and_tune()
    
    # è¾“å‡ºç»“æœ
    if changes:
        if args.apply:
            tuner.apply_to_config()
        else:
            tuner.generate_tuned_config(args.output)
    
    # ä¿å­˜æŠ¥å‘Š
    if not args.no_report:
        tuner.save_report()
    
    print("\n" + "=" * 60)
    print("è°ƒä¼˜å®Œæˆ!")
    print("=" * 60)
    
    if changes:
        print(f"\nå…± {len(changes)} é¡¹è°ƒä¼˜å»ºè®®:")
        for change in changes:
            print(f"  â€¢ {change.param_path}: {change.old_value} â†’ {change.new_value}")
        
        if not args.apply:
            print(f"\næç¤º: ä½¿ç”¨ --apply å‚æ•°å¯ç›´æ¥åº”ç”¨åˆ°é…ç½®æ–‡ä»¶")
    else:
        print("\nå½“å‰é…ç½®å·²æ˜¯æœ€ä¼˜ï¼Œæ— éœ€è°ƒæ•´")


if __name__ == '__main__':
    main()
