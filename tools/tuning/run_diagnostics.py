#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TurtleBot1 é…ç½®è¯Šæ–­ä¸è°ƒä¼˜å·¥å…·

ä½¿ç”¨æ–¹æ³•:
  # ä» ROS bag æ–‡ä»¶åˆ†æ
  python -m tools.tuning.run_diagnostics --bag /path/to/recording.bag
  
  # ä» JSON è¯Šæ–­æ•°æ®åˆ†æ
  python -m tools.tuning.run_diagnostics --json /path/to/diagnostics.json
  
  # å®æ—¶æ”¶é›†å¹¶åˆ†æ (éœ€è¦ ROS ç¯å¢ƒ)
  python -m tools.tuning.run_diagnostics --live --duration 60
  
  # æŒ‡å®šè¾“å‡ºç›®å½•
  python -m tools.tuning.run_diagnostics --bag data.bag --output ./tuned_configs

å‰ææ¡ä»¶:
  1. Python 3.7+
  2. numpy, pyyaml åŒ…
  3. å¯¹äº --bag æ¨¡å¼: rosbag åŒ…
  4. å¯¹äº --live æ¨¡å¼: ROS ç¯å¢ƒ (source /opt/ros/noetic/setup.bash)

è¾“å‡º:
  - tuned_turtlebot1.yaml: ä¼˜åŒ–åçš„é…ç½®æ–‡ä»¶
  - diagnostics_report.txt: è¯Šæ–­æŠ¥å‘Š
  - analysis_summary.json: åˆ†ææ‘˜è¦
"""

import argparse
import sys
import os
import json
import yaml
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from tools.tuning.diagnostics_analyzer import DiagnosticsAnalyzer, AnalysisResult, TuningCategory
from tools.tuning.config_generator import ConfigGenerator
from tools.tuning.data_collector import (
    CollectionConfig, 
    RosbagCollector, 
    LiveCollector, 
    JsonFileCollector,
    save_samples_to_json
)


# é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
DEFAULT_CONFIG_PATH = PROJECT_ROOT / "controller_ros" / "config" / "turtlebot1.yaml"


def print_banner():
    """æ‰“å°å·¥å…·æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         TurtleBot1 é…ç½®è¯Šæ–­ä¸è°ƒä¼˜å·¥å…· v1.0                       â•‘
â•‘                                                                  â•‘
â•‘  åŠŸèƒ½: åˆ†ææ§åˆ¶å™¨è¯Šæ–­æ•°æ®ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–é…ç½®                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)


def print_prerequisites():
    """æ‰“å°å‰ææ¡ä»¶"""
    print("\n" + "=" * 60)
    print("å‰ææ¡ä»¶æ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥ numpy
    try:
        import numpy as np
        print(f"âœ“ numpy: {np.__version__}")
    except ImportError:
        print("âœ— numpy: æœªå®‰è£… (pip install numpy)")
        return False
    
    # æ£€æŸ¥ yaml
    try:
        import yaml
        print(f"âœ“ pyyaml: {yaml.__version__}")
    except ImportError:
        print("âœ— pyyaml: æœªå®‰è£… (pip install pyyaml)")
        return False
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if DEFAULT_CONFIG_PATH.exists():
        print(f"âœ“ é…ç½®æ–‡ä»¶: {DEFAULT_CONFIG_PATH}")
    else:
        print(f"âœ— é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {DEFAULT_CONFIG_PATH}")
        return False
    
    print("=" * 60)
    return True


def load_config(config_path: str = None) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    path = Path(config_path) if config_path else DEFAULT_CONFIG_PATH
    
    if not path.exists():
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        sys.exit(1)
    
    with open(path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"å·²åŠ è½½é…ç½®: {path}")
    return config


def progress_bar(current: int, total: int, width: int = 40):
    """æ˜¾ç¤ºè¿›åº¦æ¡"""
    if total == 0:
        return
    progress = current / total
    filled = int(width * progress)
    bar = 'â–ˆ' * filled + 'â–‘' * (width - filled)
    print(f"\rè¿›åº¦: [{bar}] {current}/{total} ({progress*100:.1f}%)", end='', flush=True)


def print_analysis_results(results: list, summary: dict):
    """æ‰“å°åˆ†æç»“æœ"""
    print("\n" + "=" * 60)
    print("åˆ†ææ‘˜è¦")
    print("=" * 60)
    
    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    print(f"\næ ·æœ¬æ•°: {summary.get('total_samples', 'N/A')}")
    
    mpc = summary.get('mpc', {})
    if mpc:
        print(f"\nMPC æ€§èƒ½:")
        print(f"  - æˆåŠŸç‡: {mpc.get('success_rate', 'N/A')}%")
        print(f"  - å¹³å‡æ±‚è§£æ—¶é—´: {mpc.get('avg_solve_time_ms', 'N/A')}ms")
        print(f"  - 95%åˆ†ä½æ±‚è§£æ—¶é—´: {mpc.get('p95_solve_time_ms', 'N/A')}ms")
        print(f"  - å¤‡ç”¨æ§åˆ¶å™¨æ¿€æ´»ç‡: {mpc.get('backup_rate', 'N/A')}%")
    
    tracking = summary.get('tracking', {})
    if tracking:
        print(f"\nè·Ÿè¸ªè¯¯å·®:")
        if 'lateral' in tracking:
            lat = tracking['lateral']
            print(f"  - æ¨ªå‘: avg={lat.get('avg_cm', 'N/A')}cm, max={lat.get('max_cm', 'N/A')}cm")
        if 'longitudinal' in tracking:
            lon = tracking['longitudinal']
            print(f"  - çºµå‘: avg={lon.get('avg_cm', 'N/A')}cm, max={lon.get('max_cm', 'N/A')}cm")
        if 'heading' in tracking:
            head = tracking['heading']
            print(f"  - èˆªå‘: avg={head.get('avg_deg', 'N/A')}Â°, max={head.get('max_deg', 'N/A')}Â°")
    
    timeout = summary.get('timeout', {})
    if timeout:
        print(f"\nè¶…æ—¶ç»Ÿè®¡:")
        print(f"  - é‡Œç¨‹è®¡è¶…æ—¶æ¬¡æ•°: {timeout.get('odom_timeout_count', 0)}")
        print(f"  - è½¨è¿¹è¶…æ—¶æ¬¡æ•°: {timeout.get('traj_timeout_count', 0)}")
        print(f"  - å®½é™æœŸè¶…æ—¶æ¬¡æ•°: {timeout.get('traj_grace_exceeded_count', 0)}")
    
    # æ‰“å°ä¼˜åŒ–å»ºè®®
    print("\n" + "=" * 60)
    print("ä¼˜åŒ–å»ºè®®")
    print("=" * 60)
    
    if not results:
        print("\nâœ“ å½“å‰é…ç½®è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€è°ƒæ•´")
        return
    
    # æŒ‰è°ƒä¼˜åˆ†ç±»å’Œä¸¥é‡ç¨‹åº¦åˆ†ç»„
    tunable_results = [r for r in results if r.tuning_category == TuningCategory.TUNABLE]
    design_results = [r for r in results if r.tuning_category == TuningCategory.DESIGN]
    safety_results = [r for r in results if r.tuning_category == TuningCategory.SAFETY]
    diagnostic_results = [r for r in results if r.tuning_category == TuningCategory.DIAGNOSTIC]
    
    # å¯è°ƒä¼˜å‚æ•°
    if tunable_results:
        critical = [r for r in tunable_results if r.severity == 'critical']
        warning = [r for r in tunable_results if r.severity == 'warning']
        info = [r for r in tunable_results if r.severity == 'info']
        
        print("\n" + "-" * 40)
        print("å¯è°ƒä¼˜å‚æ•° (å»ºè®®é‡‡çº³)")
        print("-" * 40)
        
        if critical:
            print(f"\nğŸ”´ ä¸¥é‡é—®é¢˜ ({len(critical)}é¡¹):")
            for r in critical:
                print(f"  [{r.parameter}]")
                print(f"    å½“å‰å€¼: {r.current_value} â†’ å»ºè®®å€¼: {r.suggested_value}")
                print(f"    åŸå› : {r.reason}")
        
        if warning:
            print(f"\nğŸŸ¡ è­¦å‘Š ({len(warning)}é¡¹):")
            for r in warning:
                print(f"  [{r.parameter}]")
                print(f"    å½“å‰å€¼: {r.current_value} â†’ å»ºè®®å€¼: {r.suggested_value}")
                print(f"    åŸå› : {r.reason}")
        
        if info:
            print(f"\nğŸ”µ å»ºè®® ({len(info)}é¡¹):")
            for r in info:
                print(f"  [{r.parameter}]")
                print(f"    å½“å‰å€¼: {r.current_value} â†’ å»ºè®®å€¼: {r.suggested_value}")
                print(f"    åŸå› : {r.reason}")
    
    # è®¾è®¡å‚æ•°ï¼ˆä»…è¯Šæ–­ä¿¡æ¯ï¼‰
    if design_results:
        print("\n" + "-" * 40)
        print("è®¾è®¡å‚æ•° (ä¸å»ºè®®è‡ªåŠ¨è°ƒä¼˜)")
        print("-" * 40)
        for r in design_results:
            print(f"  âšª [{r.parameter}]")
            print(f"    {r.reason}")
    
    # å®‰å…¨å‚æ•°ï¼ˆä»…è¯Šæ–­ä¿¡æ¯ï¼‰
    if safety_results:
        print("\n" + "-" * 40)
        print("å®‰å…¨å‚æ•° (ä¸å»ºè®®è‡ªåŠ¨è°ƒæ•´)")
        print("-" * 40)
        for r in safety_results:
            # omega_max=0 æ˜¯é…ç½®é”™è¯¯ï¼Œéœ€è¦ä¿®å¤
            if r.category == 'config_error':
                print(f"  ğŸ”´ [{r.parameter}] (é…ç½®é”™è¯¯ï¼Œéœ€ä¿®å¤)")
                print(f"    å½“å‰å€¼: {r.current_value} â†’ å»ºè®®å€¼: {r.suggested_value}")
                print(f"    åŸå› : {r.reason}")
            else:
                print(f"  âšª [{r.parameter}]")
                print(f"    {r.reason}")


def run_analysis(samples: list, config: dict, output_dir: Path, config_path: str):
    """è¿è¡Œåˆ†æå¹¶ç”Ÿæˆè¾“å‡º"""
    print("\n" + "=" * 60)
    print("å¼€å§‹åˆ†æ")
    print("=" * 60)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DiagnosticsAnalyzer(config)
    
    # æ·»åŠ æ ·æœ¬
    print(f"\nå¤„ç† {len(samples)} ä¸ªæ ·æœ¬...")
    for i, sample in enumerate(samples):
        analyzer.add_sample(sample)
        if (i + 1) % 500 == 0:
            print(f"  å·²å¤„ç†: {i + 1}/{len(samples)}")
    
    # æ‰§è¡Œåˆ†æ
    print("\næ‰§è¡Œåˆ†æ...")
    results = analyzer.analyze()
    summary = analyzer.get_summary()
    
    # æ‰“å°ç»“æœ
    print_analysis_results(results, summary)
    
    # ç”Ÿæˆä¼˜åŒ–é…ç½®
    print("\n" + "=" * 60)
    print("ç”Ÿæˆä¼˜åŒ–é…ç½®")
    print("=" * 60)
    
    generator = ConfigGenerator(config, config_path)
    
    # åº”ç”¨æ‰€æœ‰ warning å’Œ critical çº§åˆ«çš„å»ºè®®
    optimized_config = generator.apply_results(
        results, 
        min_confidence=0.6,
        severity_filter=['warning', 'critical']
    )
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆä¼˜åŒ–åçš„ YAML æ–‡ä»¶
    output_yaml = output_dir / "tuned_turtlebot1.yaml"
    generator.generate_yaml(optimized_config, str(output_yaml), summary)
    print(f"\nâœ“ ä¼˜åŒ–é…ç½®å·²ä¿å­˜: {output_yaml}")
    
    # ä¿å­˜åˆ†ææ‘˜è¦
    summary_file = output_dir / "analysis_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'sample_count': len(samples),
            'summary': summary,
            'results': [
                {
                    'category': r.category,
                    'severity': r.severity,
                    'parameter': r.parameter,
                    'current_value': r.current_value,
                    'suggested_value': r.suggested_value,
                    'reason': r.reason,
                    'confidence': r.confidence,
                    'tuning_category': r.tuning_category.value
                }
                for r in results
            ]
        }, f, indent=2, ensure_ascii=False)
    print(f"âœ“ åˆ†ææ‘˜è¦å·²ä¿å­˜: {summary_file}")
    
    # ä¿å­˜è¯Šæ–­æŠ¥å‘Š
    report_file = output_dir / "diagnostics_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("TurtleBot1 é…ç½®è¯Šæ–­æŠ¥å‘Š\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 60 + "\n\n")
        
        f.write("åˆ†ææ‘˜è¦:\n")
        f.write(json.dumps(summary, indent=2, ensure_ascii=False))
        f.write("\n\n")
        
        f.write("ä¼˜åŒ–å»ºè®®:\n")
        for r in results:
            f.write(f"\n[{r.severity.upper()}] {r.parameter}\n")
            f.write(f"  å½“å‰å€¼: {r.current_value}\n")
            f.write(f"  å»ºè®®å€¼: {r.suggested_value}\n")
            f.write(f"  åŸå› : {r.reason}\n")
            f.write(f"  ç½®ä¿¡åº¦: {r.confidence*100:.0f}%\n")
        
        f.write("\n" + "=" * 60 + "\n")
        f.write(generator.get_change_report())
    
    print(f"âœ“ è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return results, summary


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='TurtleBot1 é…ç½®è¯Šæ–­ä¸è°ƒä¼˜å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    # æ•°æ®æºé€‰é¡¹ï¼ˆäº’æ–¥ï¼‰
    source_group = parser.add_mutually_exclusive_group(required=True)
    source_group.add_argument('--bag', type=str, help='ROS bag æ–‡ä»¶è·¯å¾„')
    source_group.add_argument('--json', type=str, help='JSON è¯Šæ–­æ•°æ®æ–‡ä»¶è·¯å¾„')
    source_group.add_argument('--live', action='store_true', help='ä»å®æ—¶ ROS è¯é¢˜æ”¶é›†')
    source_group.add_argument('--demo', action='store_true', help='ä½¿ç”¨æ¼”ç¤ºæ•°æ®è¿è¡Œ')
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument('--config', type=str, default=None,
                        help=f'é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: {DEFAULT_CONFIG_PATH})')
    parser.add_argument('--output', type=str, default='./tuning_output',
                        help='è¾“å‡ºç›®å½• (é»˜è®¤: ./tuning_output)')
    parser.add_argument('--duration', type=float, default=60.0,
                        help='å®æ—¶æ”¶é›†æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 60)')
    parser.add_argument('--topic', type=str, default='/controller/diagnostics',
                        help='è¯Šæ–­è¯é¢˜åç§° (é»˜è®¤: /controller/diagnostics)')
    parser.add_argument('--max-samples', type=int, default=10000,
                        help='æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤: 10000)')
    
    args = parser.parse_args()
    
    # æ‰“å°æ¨ªå¹…
    print_banner()
    
    # æ£€æŸ¥å‰ææ¡ä»¶
    if not print_prerequisites():
        print("\nè¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–åé‡è¯•")
        sys.exit(1)
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    config_path = args.config or str(DEFAULT_CONFIG_PATH)
    
    # æ”¶é›†é…ç½®
    collection_config = CollectionConfig(
        diagnostics_topic=args.topic,
        max_samples=args.max_samples
    )
    
    # æ”¶é›†æ•°æ®
    samples = []
    
    if args.bag:
        print(f"\nä» ROS bag æ–‡ä»¶æ”¶é›†æ•°æ®: {args.bag}")
        collector = RosbagCollector(args.bag, collection_config)
        count = collector.collect(progress_callback=progress_bar)
        print()  # æ¢è¡Œ
        samples = collector.get_samples()
        
    elif args.json:
        print(f"\nä» JSON æ–‡ä»¶åŠ è½½æ•°æ®: {args.json}")
        collector = JsonFileCollector(args.json, collection_config)
        count = collector.collect()
        samples = collector.get_samples()
        
    elif args.live:
        print(f"\nä»å®æ—¶è¯é¢˜æ”¶é›†æ•°æ®...")
        print("æç¤º: ç¡®ä¿æ§åˆ¶å™¨æ­£åœ¨è¿è¡Œå¹¶å‘å¸ƒè¯Šæ–­æ•°æ®")
        
        def live_progress(samples, elapsed):
            print(f"\rå·²æ”¶é›†: {samples} æ ·æœ¬, å·²ç”¨æ—¶: {elapsed:.1f}ç§’", end='', flush=True)
        
        collector = LiveCollector(collection_config)
        count = collector.collect(
            duration_sec=args.duration,
            progress_callback=live_progress
        )
        print()  # æ¢è¡Œ
        samples = collector.get_samples()
        
        # ä¿å­˜æ”¶é›†çš„æ•°æ®
        if samples:
            output_dir = Path(args.output)
            output_dir.mkdir(parents=True, exist_ok=True)
            save_samples_to_json(samples, str(output_dir / "collected_diagnostics.json"))
    
    elif args.demo:
        print("\nä½¿ç”¨æ¼”ç¤ºæ•°æ®...")
        samples = generate_demo_data()
    
    # æ£€æŸ¥æ ·æœ¬æ•°
    if not samples:
        print("\né”™è¯¯: æœªæ”¶é›†åˆ°ä»»ä½•æ•°æ®")
        print("è¯·æ£€æŸ¥:")
        print("  1. æ•°æ®æºæ˜¯å¦æ­£ç¡®")
        print("  2. è¯Šæ–­è¯é¢˜æ˜¯å¦æ­£ç¡®")
        print("  3. æ§åˆ¶å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œ")
        sys.exit(1)
    
    print(f"\næ”¶é›†åˆ° {len(samples)} ä¸ªæ ·æœ¬")
    
    # è¿è¡Œåˆ†æ
    output_dir = Path(args.output)
    results, summary = run_analysis(samples, config, output_dir, config_path)
    
    # å®Œæˆ
    print("\n" + "=" * 60)
    print("è¯Šæ–­å®Œæˆ!")
    print("=" * 60)
    print(f"\nè¾“å‡ºæ–‡ä»¶ä½äº: {output_dir.absolute()}")
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹ diagnostics_report.txt äº†è§£è¯¦ç»†åˆ†æ")
    print("  2. æ£€æŸ¥ tuned_turtlebot1.yaml ä¸­çš„ä¼˜åŒ–é…ç½®")
    print("  3. å°†ä¼˜åŒ–é…ç½®å¤åˆ¶åˆ° controller_ros/config/ ç›®å½•")
    print("  4. é‡æ–°å¯åŠ¨æ§åˆ¶å™¨æµ‹è¯•æ•ˆæœ")


def generate_demo_data() -> list:
    """ç”Ÿæˆæ¼”ç¤ºæ•°æ® - æ¨¡æ‹ŸçœŸå®æ§åˆ¶å™¨è¡Œä¸º
    
    ç”Ÿæˆçš„æ•°æ®ä¸¥æ ¼éµå¾ª DiagnosticsV2.to_ros_msg() çš„è¾“å‡ºæ ¼å¼ã€‚
    
    ç”Ÿæˆçš„æ•°æ®å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
    1. æ—¶é—´ç›¸å…³æ€§ - è¿ç»­å¸§çš„è¯¯å·®ç›¸è¿‘
    2. çŠ¶æ€è½¬æ¢ - æ¨¡æ‹Ÿ MPC å¶å°”å¤±è´¥åæ¢å¤
    3. å‘¨æœŸæ€§æ³¢åŠ¨ - æ¨¡æ‹Ÿè½¨è¿¹è·Ÿè¸ªçš„å‘¨æœŸæ€§è¯¯å·®
    """
    import numpy as np
    from universal_controller.core.enums import ControllerState
    
    samples = []
    np.random.seed(42)
    
    # çŠ¶æ€å˜é‡ï¼ˆæ¨¡æ‹Ÿæ—¶é—´ç›¸å…³æ€§ï¼‰
    current_lateral_error = 0.05
    current_longitudinal_error = 0.10
    current_heading_error = 0.05
    current_solve_time = 10.0
    mpc_fail_streak = 0
    state = ControllerState.NORMAL
    
    for i in range(500):
        # æ¨¡æ‹Ÿ MPC æ±‚è§£æ—¶é—´çš„æ—¶é—´ç›¸å…³æ€§ï¼ˆå¸¦éšæœºæ‰°åŠ¨ï¼‰
        current_solve_time = 0.9 * current_solve_time + 0.1 * (np.random.exponential(8) + 5)
        current_solve_time = np.clip(current_solve_time, 3, 50)
        
        # æ¨¡æ‹Ÿ MPC æˆåŠŸ/å¤±è´¥ï¼ˆè¿ç»­å¤±è´¥æ›´å¯èƒ½ç»§ç»­å¤±è´¥ï¼‰
        if mpc_fail_streak > 0:
            mpc_success = np.random.random() > 0.3  # å¤±è´¥åæ¢å¤æ¦‚ç‡ 70%
        else:
            mpc_success = np.random.random() > 0.08  # æ­£å¸¸å¤±è´¥ç‡ 8%
        
        if not mpc_success:
            mpc_fail_streak += 1
        else:
            mpc_fail_streak = 0
        
        # çŠ¶æ€è½¬æ¢é€»è¾‘ (ä½¿ç”¨æšä¸¾)
        if mpc_fail_streak >= 5:
            state = ControllerState.BACKUP_ACTIVE
        elif mpc_fail_streak >= 3:
            state = ControllerState.MPC_DEGRADED
        elif mpc_fail_streak == 0 and state != ControllerState.NORMAL:
            state = ControllerState.NORMAL
        
        backup_active = (state == ControllerState.BACKUP_ACTIVE)
        
        # æ¨¡æ‹Ÿè·Ÿè¸ªè¯¯å·®çš„æ—¶é—´ç›¸å…³æ€§ï¼ˆå¸¦å‘¨æœŸæ€§æ³¢åŠ¨ï¼‰
        phase = i * 0.1  # æ¨¡æ‹Ÿè½¨è¿¹å‘¨æœŸ
        
        # è¯¯å·®å¹³æ»‘å˜åŒ–
        target_lateral = 0.05 + 0.03 * np.sin(phase * 0.5) + np.random.normal(0, 0.01)
        target_longitudinal = 0.10 + 0.05 * np.sin(phase * 0.3) + np.random.normal(0, 0.02)
        target_heading = 0.05 + 0.03 * np.sin(phase * 0.7) + np.random.normal(0, 0.01)
        
        current_lateral_error = 0.8 * current_lateral_error + 0.2 * abs(target_lateral)
        current_longitudinal_error = 0.8 * current_longitudinal_error + 0.2 * abs(target_longitudinal)
        current_heading_error = 0.8 * current_heading_error + 0.2 * abs(target_heading)
        
        # å¤‡ç”¨æ§åˆ¶å™¨æ¿€æ´»æ—¶è¯¯å·®ä¼šå¢å¤§
        if backup_active:
            current_lateral_error *= 1.5
            current_longitudinal_error *= 1.5
        
        # è®¡ç®—è·Ÿè¸ªè´¨é‡è¯„åˆ† (ç®€åŒ–ç‰ˆ)
        tracking_quality_score = max(0, 100 - current_lateral_error * 200 - current_longitudinal_error * 100 - current_heading_error * 50)
        if tracking_quality_score >= 90:
            tracking_quality_rating = 'excellent'
        elif tracking_quality_score >= 70:
            tracking_quality_rating = 'good'
        elif tracking_quality_score >= 50:
            tracking_quality_rating = 'fair'
        else:
            tracking_quality_rating = 'poor'
        
        # æ¨¡æ‹Ÿè¶…æ—¶äº‹ä»¶ï¼ˆå¶å‘ï¼‰
        odom_timeout = np.random.random() > 0.98
        traj_timeout = np.random.random() > 0.94
        traj_grace_exceeded = traj_timeout and np.random.random() > 0.9
        imu_timeout = np.random.random() > 0.99
        
        # æ¨¡æ‹Ÿæ•°æ®å»¶è¿Ÿï¼ˆæœ‰æ—¶é—´ç›¸å…³æ€§ï¼‰
        base_odom_age = 30 + 20 * np.sin(i * 0.05)
        base_traj_age = 150 + 100 * np.sin(i * 0.03)
        base_imu_age = 10 + 5 * np.sin(i * 0.08)
        
        # ç”Ÿæˆä¸ DiagnosticsV2.to_ros_msg() å®Œå…¨ä¸€è‡´çš„æ ¼å¼
        sample = {
            'header': {
                'stamp': i * 0.05,  # 20Hz
                'frame_id': ''
            },
            'state': int(state),  # è½¬æ¢ä¸º int ä»¥åŒ¹é… ROS æ¶ˆæ¯æ ¼å¼
            'mpc_success': mpc_success,
            'mpc_solve_time_ms': current_solve_time,
            'backup_active': backup_active,
            
            # MPC å¥åº·çŠ¶æ€
            'mpc_health': {
                'kkt_residual': np.random.exponential(0.0001),
                'condition_number': np.random.exponential(1e5),
                'consecutive_near_timeout': mpc_fail_streak,
                'degradation_warning': mpc_fail_streak >= 2,
                'can_recover': mpc_fail_streak < 5
            },
            
            # ä¸€è‡´æ€§æŒ‡æ ‡
            'consistency': {
                'curvature': np.clip(0.7 + np.random.normal(0, 0.1), 0.3, 1.0),
                'velocity_dir': np.clip(0.8 + np.random.normal(0, 0.1), 0.4, 1.0),
                'temporal': np.clip(0.7 + np.random.normal(0, 0.1), 0.3, 1.0),
                'alpha_soft': np.clip(0.6 + np.random.normal(0, 0.15), 0.1, 1.0),
                'data_valid': np.random.random() > 0.02
            },
            
            # çŠ¶æ€ä¼°è®¡å™¨å¥åº·
            'estimator_health': {
                'covariance_norm': np.random.exponential(0.1),
                'innovation_norm': np.random.exponential(0.05),
                'slip_probability': np.clip(np.random.exponential(0.1), 0, 1),
                'imu_drift_detected': np.random.random() > 0.98,
                'imu_bias': [np.random.normal(0, 0.001) for _ in range(3)],
                'imu_available': True
            },
            
            # è·Ÿè¸ªè¯¯å·®å’Œè´¨é‡è¯„ä¼°
            'tracking': {
                'lateral_error': current_lateral_error,
                'longitudinal_error': current_longitudinal_error,
                'heading_error': current_heading_error,
                'prediction_error': abs(np.random.normal(0.03, 0.01)),
                'quality_score': tracking_quality_score,
                'quality_rating': tracking_quality_rating
            },
            
            # åæ ‡å˜æ¢çŠ¶æ€
            'transform': {
                'tf2_available': True,
                'tf2_injected': True,
                'fallback_duration_ms': 0 if np.random.random() > 0.05 else np.random.exponential(50),
                'accumulated_drift': np.random.exponential(0.01),
                'source_frame': 'base_link',
                'target_frame': 'odom',
                'error_message': '' if np.random.random() > 0.02 else 'TF2 temporarily unavailable'
            },
            
            # è¶…æ—¶çŠ¶æ€
            'timeout': {
                'odom_timeout': odom_timeout,
                'traj_timeout': traj_timeout,
                'traj_grace_exceeded': traj_grace_exceeded,
                'imu_timeout': imu_timeout,
                'last_odom_age_ms': base_odom_age + np.random.exponential(20),
                'last_traj_age_ms': base_traj_age + np.random.exponential(50),
                'last_imu_age_ms': base_imu_age + np.random.exponential(5),
                'in_startup_grace': i < 10
            },
            
            # æ§åˆ¶å‘½ä»¤
            'cmd': {
                'vx': np.clip(0.25 + 0.1 * np.sin(phase * 0.2) + np.random.normal(0, 0.02), 0, 0.5),
                'vy': 0.0,
                'vz': 0.0,
                'omega': np.clip(0.2 * np.sin(phase * 0.5) + np.random.normal(0, 0.05), -1.0, 1.0),
                'frame_id': 'base_link'
            },
            
            # è¿‡æ¸¡è¿›åº¦
            'transition_progress': 1.0 if state == ControllerState.NORMAL else np.clip(0.5 + np.random.normal(0, 0.1), 0, 1),
            
            # å®‰å…¨çŠ¶æ€ (é¡¶å±‚å­—æ®µï¼Œä¸ DiagnosticsV2.to_ros_msg() ä¸€è‡´)
            'safety_check_passed': np.random.random() > 0.02,
            'emergency_stop': np.random.random() > 0.995,
            
            # ROS èŠ‚ç‚¹å±‚å­—æ®µ (ç”± controller_ros/node/base_node.py æ·»åŠ )
            # æ³¨æ„: è¿™äº›å­—æ®µåœ¨é ROS ç¯å¢ƒä¸‹ä¸å­˜åœ¨ï¼Œåˆ†æå™¨ä¼šä½¿ç”¨é»˜è®¤å€¼ 0
            'error_message': '',
            'consecutive_errors': mpc_fail_streak
        }
        samples.append(sample)
    
    return samples


if __name__ == '__main__':
    main()
